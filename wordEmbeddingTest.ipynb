{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback # token 계산\n",
    "import time\n",
    "# os.environ['OPENAI_API_KEY'] = \"sk-xxx\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 단어 수:  37\n",
      "\n",
      "금융통화위원회는 다음 통화정책방향 결정시까지 한국은행 기준금리를 현 수준(3.50%)에서 유지하여 통화정책을 운용하기로 하였다. 물가상승률이 둔화 흐름을지속하겠지만 상당기간 목표수준을 상회할 것으로 전망되는 만큼 현재의 긴축기조를 유지하는 것이 적절하다고 보았다. 추가 인상 필요성은 대내외 정책여건의 변화를 점검하면서 판단해 나갈 것이다.\n",
      "\n",
      "영어 문장 단어 수:  37\n",
      "\n",
      "The old, creaky wooden door swung open slowly, revealing a dimly lit room filled with dusty books and antique furniture, while a faint scent of lavender lingered in the air, evoking a sense of nostalgia and mystery.\n"
     ]
    }
   ],
   "source": [
    "kor_text = \"\"\"\n",
    "금융통화위원회는 다음 통화정책방향 결정시까지 한국은행 기준금리를 현 수준(3.50%)에서 유지하여 통화정책을 운용하기로 하였다. 물가상승률이 둔화 흐름을지속하겠지만 상당기간 목표수준을 상회할 것으로 전망되는 만큼 현재의 긴축기조를 유지하는 것이 적절하다고 보았다. 추가 인상 필요성은 대내외 정책여건의 변화를 점검하면서 판단해 나갈 것이다.\n",
    "\"\"\"\n",
    "\n",
    "eng_text = \"\"\"\n",
    "The old, creaky wooden door swung open slowly, revealing a dimly lit room filled with dusty books and antique furniture, while a faint scent of lavender lingered in the air, evoking a sense of nostalgia and mystery.\"\"\"\n",
    "\n",
    "print(\"한국어 문장 단어 수: \", len(kor_text.split(' ')))\n",
    "print(kor_text)\n",
    "\n",
    "print(\"영어 문장 단어 수: \", len(eng_text.split(' ')))\n",
    "print(eng_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  128\n",
      "한국어 문장 임베딩 시간:  1.0295090675354004\n",
      "영어 문장 임베딩 길이:  128\n",
      "영어 문장 임베딩 시간:  0.4645390510559082\n"
     ]
    }
   ],
   "source": [
    "## Aleph Alpha : 서로 다른 구조(docummnet-query)의 문장 Asymmetric / 같은 구조 symmetric(same) 유사성을 볼 때 사용, embedding size를 줄일 수 있다.\n",
    "## pip install aleph_alpha_client 설치 + https://app.aleph-alpha.com/ 가입 후 API KEY 발급 받아야 함\n",
    "os.environ['ALEPH_ALPHA_API_KEY'] = \"...\"\n",
    "\n",
    "## Asymmetric\n",
    "\n",
    "from langchain.embeddings import AlephAlphaAsymmetricSemanticEmbedding\n",
    "max_output = 128 # 5120 dimensions\n",
    "embeddings = AlephAlphaAsymmetricSemanticEmbedding(compress_to_size=128)\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  128\n",
      "한국어 문장 임베딩 시간:  1.316870927810669\n",
      "영어 문장 임베딩 길이:  128\n",
      "영어 문장 임베딩 시간:  0.3432149887084961\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Symmetric\n",
    "\n",
    "from langchain.embeddings import AlephAlphaSymmetricSemanticEmbedding\n",
    "max_output = 128 # 5120 dimensions\n",
    "embeddings = AlephAlphaSymmetricSemanticEmbedding(compress_to_size=128)\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  768\n",
      "한국어 문장 임베딩 시간:  1.168846845626831\n",
      "영어 문장 임베딩 길이:  768\n",
      "영어 문장 임베딩 시간:  0.3746333122253418\n"
     ]
    }
   ],
   "source": [
    "## Cohere : embedding 횟수로 가격을 받음 1000회 1달라\n",
    "## pip install cohere 설치 + https://dashboard.cohere.ai/api-keys/ 가입 후 API KEY 발급 받아야 함\n",
    "os.environ['COHERE_API_KEY']='...'\n",
    "\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "max_output = 4096\n",
    "embeddings = CohereEmbeddings(model='embed-multilingual-v2.0')\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Google Cloud Platform Vertex AI PaLM : \n",
    "## !pip install google-cloud-aiplatform 설치 + https://dashboard.cohere.ai/api-keys/ 가입 후 API KEY 발급 받아야 함\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='...'\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "\n",
    "max_output = 4096\n",
    "embeddings = VertexAIEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  768\n",
      "한국어 문장 임베딩 시간:  0.20738792419433594\n",
      "영어 문장 임베딩 길이:  768\n",
      "영어 문장 임베딩 시간:  0.04394221305847168\n"
     ]
    }
   ],
   "source": [
    "## Hugging Face Hub : Cost 0에 CPU/GPU MPS 까지 지원\n",
    "## default : sentence-transformers/all-mpnet-base-v2 모델 이외에 다양한 Task 모델 지원\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "max_output = 768\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "한국어 문장 임베딩 길이:  768\n",
      "한국어 문장 임베딩 시간:  0.13651299476623535\n",
      "영어 문장 임베딩 길이:  768\n",
      "영어 문장 임베딩 시간:  0.12634706497192383\n"
     ]
    }
   ],
   "source": [
    "## InstructEmbeddings : Cost 0에 CPU/GPU/MPS 까지 지원\n",
    "## default : hkunlp/instructor-large 모델 이외에 다양한 Task 모델 지원\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "max_output = 0\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  512\n",
      "한국어 문장 임베딩 시간:  2.2679479122161865\n",
      "영어 문장 임베딩 길이:  512\n",
      "영어 문장 임베딩 시간:  1.4199268817901611\n"
     ]
    }
   ],
   "source": [
    "## Jina : Cost 0에 CPU/GPU/MPS 까지 지원\n",
    "## default : ViT-B-32::openai 모델 이외에 다양한 Task 모델 지원\n",
    "## pip install jina + https://cloud.jina.ai/ 가입 후 Token 발급 받아야 함 + model 생성\n",
    "\n",
    "\n",
    "from langchain.embeddings import JinaEmbeddings\n",
    "max_output = 0\n",
    "embeddings = JinaEmbeddings(jina_auth_token=jina_auth_token, model_name=\"ViT-B-32::openai\")\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llama-cpp : LLama model cpp version \n",
    "## !pip install llama-cpp-python / llamamodel 사용\n",
    "\n",
    "\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "max_output = 0\n",
    "embeddings = LlamaCppEmbeddings(model_path='/')\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MosaicML embeddings\n",
    "# sign up for an account: https://forms.mosaicml.com/demo?utm_source=langchain\n",
    "# pip install --upgrade mosaicml-cli \n",
    "from getpass import getpass\n",
    "\n",
    "MOSAICML_API_TOKEN = getpass()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MOSAICML_API_TOKEN\"] = MOSAICML_API_TOKEN\n",
    "\n",
    "from langchain.embeddings import MosaicMLInstructorEmbeddings\n",
    "\n",
    "max_output = 0\n",
    "embeddings = MosaicMLInstructorEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 임베딩 길이:  1536\n",
      "한국어 문장 임베딩 시간:  0.30863404273986816\n",
      "영어 문장 임베딩 길이:  1536\n",
      "영어 문장 임베딩 시간:  0.389833927154541\n"
     ]
    }
   ],
   "source": [
    "## OpenAI Embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "max_output = 0\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI Embeddings\n",
    "from langchain.embeddings import TensorflowHubEmbeddings\n",
    "\n",
    "\n",
    "max_output = 0\n",
    "embeddings = TensorflowHubEmbeddings()\n",
    "\n",
    "start = time.time()\n",
    "kor_embed = embeddings.embed_query(kor_text)\n",
    "end = time.time()\n",
    "\n",
    "kor_cost = end - start\n",
    "kor_len = len(kor_embed)\n",
    "\n",
    "start = time.time()\n",
    "eng_embed = embeddings.embed_query(eng_text)\n",
    "end = time.time()\n",
    "eng_cost = end - start\n",
    "eng_len = len(eng_embed)\n",
    "\n",
    "print(\"한국어 문장 임베딩 길이: \", kor_len)\n",
    "print(\"한국어 문장 임베딩 시간: \", kor_cost)\n",
    "\n",
    "print(\"영어 문장 임베딩 길이: \", eng_len)\n",
    "print(\"영어 문장 임베딩 시간: \", eng_cost)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model|max_dim|kor_cost|eng_cost|kor_dim|eng_dim|price|\n",
    "|---|---|---|---|---|---|----|\n",
    "|AlephAlphaAsymmetricSemanticEmbedding|128~5120|1.0295090675354004|0.4645390510559082|128|128|Base Price per 1000 input tokens 0.03 (€0.006)|\n",
    "|AlephAlphaSymmetricSemanticEmbedding|128~5120|1.4380428791046143|0.3773219585418701|128|128|Base Price per 1000 input tokens 0.03 (€0.006)|\n",
    "|CohereEmbeddings|4096|1.168846845626831|0.3746333122253418|768|768|$1.0 / 1k Embeddings|\n",
    "|VertexAIEmbeddings|1024|-|-|-|-|$0.01 / 1k token|\n",
    "|HuggingFaceEmbeddings|768|0.20738792419433594|0.04394221305847168|768|768|no cost|\n",
    "|HuggingFaceInstructEmbeddings|512|0.1447281837463379|0.1259918212890625|768|768|no cost|\n",
    "|LlamaCppEmbeddings|-|-|-|-|-|-|\n",
    "|JinaEmbeddings|512|2.2679479122161865|1.4199268817901611|512|512|usage per credit(1000 req)|\n",
    "|OpenAIEmbeddings|1536|0.30863404273986816|0.389833927154541|1536|1536|$0.0004 / 1k tokens|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
